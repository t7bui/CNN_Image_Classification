{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Understand Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train shape: (50000, 32, 32, 3)\n",
      "[59 62 63]\n",
      "Looks like we need to convert in between (0,1) by divide elements by 255 \n",
      "\n",
      "Y Train shape: (50000, 1)\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "Looks like we have 10 unique classes for our data\n"
     ]
    }
   ],
   "source": [
    "print(\"X Train shape:\", x_train.shape)\n",
    "print(x_train[0][0][0])\n",
    "print(\"Looks like we need to convert in between (0,1) by divide elements by 255 \\n\")\n",
    "print(\"Y Train shape:\", y_train.shape)\n",
    "print(np.unique(y_train))\n",
    "print(\"Looks like we have 10 unique classes for our data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 32, 32, 3)\n",
      "y_train.shape (50000,)\n"
     ]
    }
   ],
   "source": [
    "# Convert RGB to decimal in between [0,1] => 255 = 1, 0 = 0\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Flatten our target dataset\n",
    "y_train, y_test = y_train.flatten(), y_test.flatten()\n",
    "print(\"x_train.shape:\", x_train.shape)\n",
    "print(\"y_train.shape\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 10\n"
     ]
    }
   ],
   "source": [
    "# Get number of target classes\n",
    "k_class = len(np.unique(y_train))\n",
    "print(\"Number of Classes:\", k_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_and_loss(acc, val_acc, loss, val_loss, epochs_range, model_no):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.suptitle(\"{}\" .format(model_no))\n",
    "    plt.savefig('./{}.png' .format(model_no))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(fitted_model):\n",
    "    acc = fitted_model.history['accuracy']\n",
    "    avg_acc = np.mean(acc)\n",
    "    val_acc = fitted_model.history['val_accuracy']\n",
    "    avg_valAcc = np.mean(val_acc)\n",
    "\n",
    "    loss = fitted_model.history['loss']\n",
    "    avg_loss = np.mean(loss)\n",
    "    val_loss = fitted_model.history['val_loss']\n",
    "    avg_val_loss = np.mean(val_loss)\n",
    "\n",
    "    print(\"Average Training accuracy: {:.2f}%\".format(avg_acc*100))\n",
    "    print(\"Average Validation accuracy: {:.2f}%\".format(avg_valAcc*100))\n",
    "    print(\"Average Loss: {:.2f}\".format(avg_loss))\n",
    "    print(\"Average Validation Loss: {:.2f}\".format(avg_val_loss))\n",
    "\n",
    "    return acc, val_acc, loss, val_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,models,optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get input dimension\n",
    "# input_dimension = x_train[0].shape\n",
    "\n",
    "# # Input layer\n",
    "# inputs = Input(shape=input_dimension)\n",
    "\n",
    "# # Convolution layers\n",
    "# x = Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "# # x = BatchNormalization()(x)\n",
    "# # x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "# # x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "# x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "# # x = BatchNormalization()(x)\n",
    "# # x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "# # x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "# x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "# # x = BatchNormalization()(x)\n",
    "# # x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "# # x = BatchNormalization()(x)\n",
    "# x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "# # Fully connected layer\n",
    "# x = Flatten()(x)\n",
    "# # x = Dropout(0.2)(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# # x = Dropout(0.2)(x)\n",
    "# x = Dense(k_class, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "earlyStop = EarlyStopping(patience=10)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy',\n",
    "                                            patience=2,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "callbacks = [earlyStop, learning_rate_reduction]\n",
    "\n",
    "opt = Adam(lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input dimension\n",
    "input_dimension = x_train[0].shape\n",
    "\n",
    "# Input layer\n",
    "inputs = Input(shape=input_dimension)\n",
    "\n",
    "# Convolution layers\n",
    "x = Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "x = Conv2D(32, (3,3), activation='relu', padding='same')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = MaxPooling2D((2,2))(x)\n",
    "\n",
    "# Fully connected layer\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(k_class, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,395,434\n",
      "Trainable params: 2,395,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_1 = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    zoom_range=0.2, shear_range=0.2,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1)\n",
    "\n",
    "train_generator = data_generator.flow(x_train, y_train, BATCH_SIZE)\n",
    "val_generator = data_generator.flow(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1562/1562 [==============================] - 175s 111ms/step - loss: 1.8089 - accuracy: 0.3123 - val_loss: 1.8674 - val_accuracy: 0.3217 - lr: 0.0010\n",
      "Epoch 2/40\n",
      "1562/1562 [==============================] - 171s 109ms/step - loss: 1.5735 - accuracy: 0.4188 - val_loss: 1.7465 - val_accuracy: 0.3751 - lr: 0.0010\n",
      "Epoch 3/40\n",
      "1562/1562 [==============================] - 172s 110ms/step - loss: 1.4683 - accuracy: 0.4627 - val_loss: 1.9512 - val_accuracy: 0.2887 - lr: 0.0010\n",
      "Epoch 4/40\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.3940 - accuracy: 0.4912\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1562/1562 [==============================] - 171s 110ms/step - loss: 1.3940 - accuracy: 0.4912 - val_loss: 1.8378 - val_accuracy: 0.3474 - lr: 0.0010\n",
      "Epoch 5/40\n",
      "1562/1562 [==============================] - 170s 109ms/step - loss: 1.2812 - accuracy: 0.5343 - val_loss: 1.8077 - val_accuracy: 0.3747 - lr: 5.0000e-04\n",
      "Epoch 6/40\n",
      "1562/1562 [==============================] - 170s 109ms/step - loss: 1.2369 - accuracy: 0.5512 - val_loss: 1.6788 - val_accuracy: 0.4151 - lr: 5.0000e-04\n",
      "Epoch 7/40\n",
      "1562/1562 [==============================] - 170s 109ms/step - loss: 1.1990 - accuracy: 0.5675 - val_loss: 1.8827 - val_accuracy: 0.3484 - lr: 5.0000e-04\n",
      "Epoch 8/40\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.1732 - accuracy: 0.5788\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1562/1562 [==============================] - 171s 109ms/step - loss: 1.1732 - accuracy: 0.5788 - val_loss: 1.7930 - val_accuracy: 0.3716 - lr: 5.0000e-04\n",
      "Epoch 9/40\n",
      "1562/1562 [==============================] - 171s 110ms/step - loss: 1.1151 - accuracy: 0.5986 - val_loss: 1.7152 - val_accuracy: 0.4072 - lr: 2.5000e-04\n",
      "Epoch 10/40\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.0935 - accuracy: 0.6050\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1562/1562 [==============================] - 171s 109ms/step - loss: 1.0935 - accuracy: 0.6050 - val_loss: 1.9322 - val_accuracy: 0.3396 - lr: 2.5000e-04\n",
      "Epoch 11/40\n",
      "1562/1562 [==============================] - 170s 109ms/step - loss: 1.0587 - accuracy: 0.6192 - val_loss: 1.8258 - val_accuracy: 0.3805 - lr: 1.2500e-04\n",
      "Epoch 12/40\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.0440 - accuracy: 0.6243\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "1562/1562 [==============================] - 170s 109ms/step - loss: 1.0440 - accuracy: 0.6243 - val_loss: 1.7767 - val_accuracy: 0.4030 - lr: 1.2500e-04\n",
      "Epoch 13/40\n",
      "1562/1562 [==============================] - 170s 109ms/step - loss: 1.0276 - accuracy: 0.6299 - val_loss: 1.7894 - val_accuracy: 0.3864 - lr: 6.2500e-05\n",
      "Epoch 14/40\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.0197 - accuracy: 0.6340\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "1562/1562 [==============================] - 171s 110ms/step - loss: 1.0197 - accuracy: 0.6340 - val_loss: 1.7776 - val_accuracy: 0.4036 - lr: 6.2500e-05\n",
      "Epoch 15/40\n",
      "1562/1562 [==============================] - 172s 110ms/step - loss: 1.0090 - accuracy: 0.6387 - val_loss: 1.7483 - val_accuracy: 0.4075 - lr: 3.1250e-05\n",
      "Epoch 16/40\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.0048 - accuracy: 0.6377\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "1562/1562 [==============================] - 170s 109ms/step - loss: 1.0048 - accuracy: 0.6377 - val_loss: 1.7658 - val_accuracy: 0.4019 - lr: 3.1250e-05\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = x_train.shape[0] // BATCH_SIZE\n",
    "\n",
    "fitted_model = model.fit(train_generator, \n",
    "                         validation_data=val_generator, \n",
    "                         steps_per_epoch=steps_per_epoch,\n",
    "                         epochs=EPOCHS,\n",
    "                         callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training accuracy: 55.65%\n",
      "Average Validation accuracy: 37.33%\n",
      "Average Loss: 1.22\n",
      "Average Validation Loss: 1.81\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (40,) and (16,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Thanh Bui\\Documents\\UCSD\\WI23\\COGS181\\COGS181\\COGS181\\final - Copy.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m epochs_range \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(EPOCHS)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m acc_1, val_acc_1, loss_1, val_loss_1 \u001b[39m=\u001b[39m get_history(fitted_model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plot_acc_and_loss(acc_1, val_acc_1, loss_1, val_loss_1, epochs_range, \u001b[39m\"\u001b[39;49m\u001b[39mModel 3\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Thanh Bui\\Documents\\UCSD\\WI23\\COGS181\\COGS181\\COGS181\\final - Copy.ipynb Cell 23\u001b[0m in \u001b[0;36mplot_acc_and_loss\u001b[1;34m(acc, val_acc, loss, val_loss, epochs_range, model_no)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m8\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39;49mplot(epochs_range, acc, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTraining Accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(epochs_range, val_acc, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation Accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Thanh%20Bui/Documents/UCSD/WI23/COGS181/COGS181/COGS181/final%20-%20Copy.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend(loc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlower right\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Thanh Bui\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\matplotlib\\pyplot.py:2824\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2823\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2824\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39;49mplot(\n\u001b[0;32m   2825\u001b[0m         \u001b[39m*\u001b[39;49margs, scalex\u001b[39m=\u001b[39;49mscalex, scaley\u001b[39m=\u001b[39;49mscaley,\n\u001b[0;32m   2826\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m({\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m: data} \u001b[39mif\u001b[39;49;00m data \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m {}), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thanh Bui\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1743\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1740\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1741\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1742\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1743\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1744\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1745\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32mc:\\Users\\Thanh Bui\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\matplotlib\\axes\\_base.py:273\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    272\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 273\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(this, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Thanh Bui\\AppData\\Local\\Programs\\PythonCodingPack\\lib\\site-packages\\matplotlib\\axes\\_base.py:399\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39myaxis\u001b[39m.\u001b[39mupdate_units(y)\n\u001b[0;32m    398\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n\u001b[1;32m--> 399\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y must have same first dimension, but \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    400\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhave shapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    401\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    402\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mx and y can be no greater than 2-D, but have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshapes \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (40,) and (16,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_range = range(EPOCHS)\n",
    "acc_1, val_acc_1, loss_1, val_loss_1 = get_history(fitted_model)\n",
    "\n",
    "plot_acc_and_loss(acc_1, val_acc_1, loss_1, val_loss_1, epochs_range, \"Model 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_3.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
